"""
VektÃ¶r veritabanÄ± yÃ¶netimi - OpenAI Embeddings ile
"""

import os
import shutil
from typing import List, Optional
from pathlib import Path

import chromadb
from chromadb.config import Settings as ChromaSettings
from langchain_openai import OpenAIEmbeddings
from langchain_chroma import Chroma
from langchain.schema import Document

from config.settings import settings

# Global vector store instance
_vector_store = None

def reset_global_vector_store():
    """Global vector store instance'Ä±nÄ± sÄ±fÄ±rla"""
    global _vector_store
    _vector_store = None
    print("ğŸ”„ Global vector store instance sÄ±fÄ±rlandÄ±")

def get_embeddings():
    """OpenAI embeddings modelini dÃ¶ndÃ¼r"""
    if not settings.OPENAI_API_KEY:
        raise ValueError("OPENAI_API_KEY environment variable is required")
    
    print(f"ğŸ”§ OpenAI Embeddings baÅŸlatÄ±lÄ±yor - Model: {settings.EMBEDDING_MODEL}")
    print(f"ğŸ”‘ API Key: {settings.OPENAI_API_KEY[:20]}...")
    
    return OpenAIEmbeddings(
        model=settings.EMBEDDING_MODEL,
        openai_api_key=settings.OPENAI_API_KEY,
        openai_api_base="https://api.openai.com/v1/"
    )

def get_vector_store():
    """
    Global vector store instance'Ä±nÄ± dÃ¶ndÃ¼r
    """
    global _vector_store
    
    if _vector_store is None:
        print("ğŸ”§ Vector store baÅŸlatÄ±lÄ±yor...")
        
        # VeritabanÄ± dizinini oluÅŸtur
        db_path = Path(settings.VECTOR_DB_PATH)
        db_path.mkdir(parents=True, exist_ok=True)
        
        # Embeddings modelini al
        embeddings = get_embeddings()
        
        # ChromaDB ayarlarÄ±
        chroma_settings = ChromaSettings(
            persist_directory=str(db_path),
            anonymized_telemetry=False
        )
        
        # Chroma vector store'u oluÅŸtur
        _vector_store = Chroma(
            collection_name="amif_documents",
            embedding_function=embeddings,
            persist_directory=str(db_path),
            client_settings=chroma_settings
        )
        
        print("âœ… Vector store hazÄ±r")
    
    return _vector_store

def reset_vector_store():
    """
    Vector store'u sÄ±fÄ±rla - mevcut collection'Ä± sil
    """
    global _vector_store
    
    print("ğŸ—‘ï¸  Mevcut vector store sÄ±fÄ±rlanÄ±yor...")
    
    # Global instance'Ä± temizle
    _vector_store = None
    
    # VeritabanÄ± dizinini sil
    db_path = Path(settings.VECTOR_DB_PATH)
    if db_path.exists():
        shutil.rmtree(db_path)
        print("âœ… VeritabanÄ± dizini silindi")
    
    # Yeni dizini oluÅŸtur
    db_path.mkdir(parents=True, exist_ok=True)
    print("âœ… Yeni veritabanÄ± dizini oluÅŸturuldu")

def add_documents_to_vector_store(documents: List[Document]) -> bool:
    """
    Belgeleri vector store'a ekle - bÃ¼yÃ¼k batch'leri bÃ¶ler
    
    Args:
        documents: Eklenecek belgeler
        
    Returns:
        bool: BaÅŸarÄ±lÄ± ise True
    """
    try:
        if not documents:
            print("âš ï¸  Eklenecek belge bulunamadÄ±")
            return False
        
        vector_store = get_vector_store()
        
        print(f"ğŸ“ {len(documents)} belge vector store'a ekleniyor...")
        
        # ChromaDB maksimum batch boyutu
        MAX_BATCH_SIZE = 5000
        
        # EÄŸer belge sayÄ±sÄ± maksimum batch boyutundan bÃ¼yÃ¼kse, bÃ¶l
        if len(documents) > MAX_BATCH_SIZE:
            print(f"ğŸ“¦ BÃ¼yÃ¼k batch tespit edildi. {MAX_BATCH_SIZE}'lik parÃ§alara bÃ¶lÃ¼nÃ¼yor...")
            
            total_added = 0
            for i in range(0, len(documents), MAX_BATCH_SIZE):
                batch = documents[i:i + MAX_BATCH_SIZE]
                batch_num = (i // MAX_BATCH_SIZE) + 1
                total_batches = (len(documents) + MAX_BATCH_SIZE - 1) // MAX_BATCH_SIZE
                
                print(f"ğŸ“¦ Batch {batch_num}/{total_batches}: {len(batch)} belge ekleniyor...")
                
                # Bu batch'i ekle
                vector_store.add_documents(batch)
                total_added += len(batch)
                
                print(f"âœ… Batch {batch_num} tamamlandÄ±. Toplam eklenen: {total_added}")
        else:
            # KÃ¼Ã§Ã¼k batch, direkt ekle
            vector_store.add_documents(documents)
            total_added = len(documents)
        
        print(f"âœ… Toplam {total_added} belge baÅŸarÄ±yla eklendi")
        return True
        
    except Exception as e:
        print(f"âŒ Belge ekleme hatasÄ±: {e}")
        return False

def search_documents(query: str, k: int = 5) -> List[Document]:
    """
    Vector store'da arama yap
    
    Args:
        query: Arama sorgusu
        k: DÃ¶ndÃ¼rÃ¼lecek sonuÃ§ sayÄ±sÄ±
        
    Returns:
        List[Document]: Bulunan belgeler
    """
    try:
        vector_store = get_vector_store()
        
        print(f"ğŸ” Arama yapÄ±lÄ±yor: '{query}' (k={k})")
        
        # Collection bilgisini kontrol et
        collection = vector_store._collection
        count = collection.count()
        print(f"ğŸ“Š Collection'da {count} dokÃ¼man var")
        
        # Similarity search yap
        results = vector_store.similarity_search(query, k=k)
        
        print(f"âœ… Arama tamamlandÄ±: {len(results)} sonuÃ§ bulundu")
        
        return results
        
    except Exception as e:
        print(f"âŒ Arama hatasÄ±: {e}")
        return []

def get_collection_info():
    """
    Collection bilgilerini dÃ¶ndÃ¼r
    """
    try:
        vector_store = get_vector_store()
        
        # Collection'daki belge sayÄ±sÄ±nÄ± al
        collection = vector_store._collection
        count = collection.count()
        
        print(f"ğŸ” Collection info - Count: {count}, Name: {collection.name}")
        
        return {
            "document_count": count,
            "collection_name": "amif_documents",
            "embedding_model": settings.EMBEDDING_MODEL
        }
        
    except Exception as e:
        print(f"âŒ Collection bilgisi alÄ±namadÄ±: {e}")
        return {
            "document_count": 0,
            "collection_name": "amif_documents",
            "embedding_model": settings.EMBEDDING_MODEL,
            "error": str(e)
        } 